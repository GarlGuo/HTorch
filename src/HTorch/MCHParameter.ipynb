{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\23128\\anaconda3\\envs\\venv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "from HTorch.MCTensor import MCTensor\n",
    "from HTorch.MCHTensor import MCHTensor, MCHParameter\n",
    "from HTorch.HTensor import manifold_maps, HParameter, HTensor\n",
    "import torch\n",
    "from torch.nn import Parameter\n",
    "from HTorch.MCTensor import MCTensor\n",
    "from torch import Tensor\n",
    "from HTorch.optimizers import RiemannianSGD, RiemannianAdam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MCHParameter(MCHTensor, Parameter):\n",
    "#     \"\"\"\n",
    "#     Subclass of torch.nn.Parameter for Riemannian optimization with MCTensor arithmetic\n",
    "#     \"\"\"\n",
    "#     @staticmethod\n",
    "#     def __new__(cls, data, manifold='PoincareBall', curvature=-1.0, nc=1, requires_grad=True):\n",
    "#         res = MCHTensor._make_subclass(cls, data, requires_grad)\n",
    "#         return res\n",
    "    \n",
    "#     def __init__(self, x, manifold='PoincareBall', curvature=-1.0, nc=1, dtype=None, device=None):\n",
    "#         if isinstance(x, MCHTensor):\n",
    "#             self.manifold = x.manifold\n",
    "#             self.curvature = x.curvature\n",
    "#             self._nc = x._nc\n",
    "#             self.res = x.res.clone()\n",
    "#         elif isinstance(x, MCTensor):\n",
    "#             self.manifold = manifold_maps[manifold]()\n",
    "#             self.curvature = curvature\n",
    "#             self._nc = x._nc\n",
    "#             self.res = x.res.clone()\n",
    "#         else:\n",
    "#             self.manifold = manifold_maps[manifold]()\n",
    "#             self.curvature = curvature\n",
    "#             self._nc = nc\n",
    "#             self.res = torch.zeros(x.size() + (nc-1,),\n",
    "#                               dtype=dtype, device=device)\n",
    "\n",
    "#     def init_weights(self, irange=1e-5):\n",
    "#         # this irange need to be controled for different floating-point precision\n",
    "#         self.data.copy_(self.manifold.init_weights(self, abs(self.curvature), irange))\n",
    "#         self.res.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mch_param before updates Parameter containing:\n",
      "Parameter(MCHParameter([0.2000, 0.1000, 0.3000], requires_grad=True)), nc=3, manifold=Lorentz, curvature=-1\n",
      "mch_dist (loss) tensor(0.3742, grad_fn=<AliasBackward0>)\n",
      "mch_param.grad tensor([0.5345, 0.2673, 0.8018])\n",
      "mch_param after updates Parameter containing:\n",
      "Parameter(MCHParameter([0.1939, 0.0970, 1.0232], requires_grad=True)), nc=3, manifold=Lorentz, curvature=-1\n",
      "\n",
      "h_dist (loss) tensor(0.3742, grad_fn=<AliasBackward0>)\n",
      "h_param.grad tensor([0.5345, 0.2673, 0.8018])\n",
      "h_param after updates Hyperbolic Parameter containing:\n",
      "Parameter(HParameter([0.1939, 0.0970, 1.0232], requires_grad=True)), manifold=Lorentz, curvature=-1\n"
     ]
    }
   ],
   "source": [
    "mch_x = MCHTensor([0.2, 0.1, 0.3], manifold='Lorentz', nc=3, curvature=-1)\n",
    "# mch_x.proj_()\n",
    "mch_param = MCHParameter(mch_x, manifold='Lorentz')\n",
    "print('mch_param before updates', mch_param)\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "rsgd_mch = RiemannianSGD([mch_param], lr=1e-2)\n",
    "# mch_dist = mch_param.Hdist(mch_param.origin(2, 1, ()))\n",
    "mch_dist = mch_param.norm()\n",
    "print('mch_dist (loss)', mch_dist)\n",
    "mch_dist.backward()\n",
    "print('mch_param.grad', mch_param.grad)\n",
    "rsgd_mch.step()\n",
    "print('mch_param after updates', mch_param)\n",
    "print()\n",
    "\n",
    "h_x = HTensor([0.2, 0.1, 0.3], manifold='Lorentz', curvature=-1)\n",
    "h_param = HParameter(h_x, manifold='Lorentz')\n",
    "rsgd_h = RiemannianSGD([h_param], lr=1e-2)\n",
    "h_dist = h_param.norm()\n",
    "h_dist.backward()\n",
    "print('h_dist (loss)', h_dist)\n",
    "print('h_param.grad', h_param.grad)\n",
    "rsgd_h.step()\n",
    "print('h_param after updates', h_param)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mch_param before updates Parameter containing:\n",
      "Parameter(MCHParameter([0.2000, 0.1000, 0.3000], requires_grad=True)), nc=3, manifold=Lorentz, curvature=-1\n",
      "mch_dist (loss) tensor(0., grad_fn=<DistBackward0>)\n",
      "mch_param.grad tensor([0., 0., 0.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\23128\\anaconda3\\envs\\venv\\lib\\site-packages\\HTorch\\optimizers\\radam.py:145: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at ..\\torch\\csrc\\utils\\python_arg_parser.cpp:1420.)\n",
      "  grad.add_(weight_decay, point)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mch_param after updates Parameter containing:\n",
      "Parameter(MCHParameter([0.2000, 0.1000, 1.0247], requires_grad=True)), nc=3, manifold=Lorentz, curvature=-1\n",
      "\n",
      "h_dist (loss) tensor(0., grad_fn=<DistBackward0>)\n",
      "h_param.grad tensor([0., 0., 0.])\n",
      "h_param after updates Hyperbolic Parameter containing:\n",
      "Parameter(HParameter([0.2000, 0.1000, 1.0247], requires_grad=True)), manifold=Lorentz, curvature=-1\n"
     ]
    }
   ],
   "source": [
    "mch_x = MCHTensor([0.2, 0.1, 0.3], manifold='Lorentz', nc=3, curvature=-1)\n",
    "# mch_x.proj_()\n",
    "mch_param = MCHParameter(mch_x, manifold='Lorentz')\n",
    "print('mch_param before updates', mch_param)\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "radam_mch = RiemannianAdam([mch_param], lr=1e-1)\n",
    "# mch_dist = mch_param.Hdist(mch_param.origin(2, 1, ()))\n",
    "mch_dist = mch_param.dist(mch_param)\n",
    "print('mch_dist (loss)', mch_dist)\n",
    "mch_dist.backward()\n",
    "print('mch_param.grad', mch_param.grad)\n",
    "radam_mch.step()\n",
    "print('mch_param after updates', mch_param)\n",
    "print()\n",
    "\n",
    "h_x = HTensor([0.2, 0.1, 0.3], manifold='Lorentz', curvature=-1)\n",
    "h_param = HParameter(h_x, manifold='Lorentz')\n",
    "radam_h = RiemannianAdam([h_param], lr=1e-1)\n",
    "h_dist = h_param.dist(h_param)\n",
    "h_dist.backward()\n",
    "print('h_dist (loss)', h_dist)\n",
    "print('h_param.grad', h_param.grad)\n",
    "radam_h.step()\n",
    "print('h_param after updates', h_param)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mch_param before updates Parameter containing:\n",
      "Parameter(MCHParameter([0.2000, 0.1000, 0.3000], requires_grad=True)), nc=3, manifold=Lorentz, curvature=-1\n",
      "mch_dist (loss) tensor([0.0005], grad_fn=<AliasBackward0>)\n",
      "mch_param.grad tensor([0., 0., 0.])\n",
      "mch_param after updates Parameter containing:\n",
      "Parameter(MCHParameter([0.2000, 0.1000, 1.0247], requires_grad=True)), nc=3, manifold=Lorentz, curvature=-1\n",
      "\n",
      "h_dist (loss) tensor([0.0005], grad_fn=<AliasBackward0>)\n",
      "h_param.grad tensor([0., 0., 0.])\n",
      "h_param after updates Hyperbolic Parameter containing:\n",
      "Parameter(HParameter([0.2000, 0.1000, 1.0247], requires_grad=True)), manifold=Lorentz, curvature=-1\n"
     ]
    }
   ],
   "source": [
    "mch_x = MCHTensor([0.2, 0.1, 0.3], manifold='Lorentz', nc=3, curvature=-1)\n",
    "mch_y = MCHTensor([0.5, 0.2, 0.6], manifold='Lorentz', nc=3, curvature=-1)\n",
    "mch_param = MCHParameter(mch_x, manifold='Lorentz')\n",
    "print('mch_param before updates', mch_param)\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "rsgd_mch = RiemannianSGD([mch_param], lr=1e-2)\n",
    "# mch_dist = mch_param.Hdist(mch_param.origin(2, 1, ()))\n",
    "mch_dist = mch_param.Hdist(mch_y)\n",
    "print('mch_dist (loss)', mch_dist)\n",
    "mch_dist.backward()\n",
    "print('mch_param.grad', mch_param.grad)\n",
    "rsgd_mch.step()\n",
    "print('mch_param after updates', mch_param)\n",
    "print()\n",
    "\n",
    "h_x = HTensor([0.2, 0.1, 0.3], manifold='Lorentz', curvature=-1)\n",
    "h_y = HTensor([0.5, 0.2, 0.6], manifold='Lorentz', curvature=-1)\n",
    "h_param = HParameter(h_x, manifold='Lorentz')\n",
    "rsgd_h = RiemannianSGD([h_param], lr=1e-2)\n",
    "h_dist = h_param.Hdist(h_y)\n",
    "h_dist.backward()\n",
    "print('h_dist (loss)', h_dist)\n",
    "print('h_param.grad', h_param.grad)\n",
    "rsgd_h.step()\n",
    "print('h_param after updates', h_param)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
